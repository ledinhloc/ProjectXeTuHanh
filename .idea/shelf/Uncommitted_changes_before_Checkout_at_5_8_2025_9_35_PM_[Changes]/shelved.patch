Index: app/src/main/java/com/example/projectxetuhanh/MainActivity.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>package com.example.projectxetuhanh;\r\n\r\nimport android.annotation.SuppressLint;\r\nimport android.app.PendingIntent;\r\nimport android.content.BroadcastReceiver;\r\nimport android.content.Context;\r\nimport android.content.Intent;\r\nimport android.content.IntentFilter;\r\nimport android.content.pm.PackageManager;\r\nimport android.content.res.ColorStateList;\r\nimport android.graphics.Color;\r\nimport android.hardware.usb.UsbDevice;\r\nimport android.hardware.usb.UsbDeviceConnection;\r\nimport android.hardware.usb.UsbManager;\r\nimport android.media.Image;\r\nimport android.os.Build;\r\nimport android.os.Bundle;\r\nimport android.util.Log;\r\n\r\nimport org.opencv.core.Core;\r\nimport org.opencv.core.CvType;\r\nimport org.opencv.core.Size;\r\n\r\nimport android.widget.ImageButton;\r\nimport android.widget.Toast;\r\n\r\nimport androidx.activity.EdgeToEdge;\r\nimport androidx.annotation.NonNull;\r\nimport androidx.annotation.OptIn;\r\nimport androidx.annotation.RequiresApi;\r\nimport androidx.appcompat.app.AppCompatActivity;\r\nimport androidx.camera.core.CameraSelector;\r\nimport androidx.camera.core.ExperimentalGetImage;\r\nimport androidx.camera.core.ImageAnalysis;\r\nimport androidx.camera.core.ImageProxy;\r\nimport androidx.camera.core.Preview;\r\nimport androidx.camera.lifecycle.ProcessCameraProvider;\r\nimport androidx.camera.view.PreviewView;\r\nimport androidx.core.content.ContextCompat;\r\nimport androidx.core.graphics.Insets;\r\nimport androidx.core.view.ViewCompat;\r\nimport androidx.core.view.WindowInsetsCompat;\r\nimport androidx.recyclerview.widget.LinearLayoutManager;\r\nimport androidx.recyclerview.widget.RecyclerView;\r\n\r\nimport com.felhr.usbserial.SerialOutputStream;\r\nimport com.felhr.usbserial.UsbSerialDevice;\r\nimport com.felhr.usbserial.UsbSerialInterface;\r\nimport com.google.common.util.concurrent.ListenableFuture;\r\n\r\nimport java.io.File;\r\nimport java.io.FileOutputStream;\r\nimport java.io.IOException;\r\nimport java.io.InputStream;\r\nimport java.nio.ByteBuffer;\r\nimport java.nio.ByteOrder;\r\nimport java.nio.charset.StandardCharsets;\r\nimport java.util.ArrayList;\r\nimport java.util.Arrays;\r\nimport java.util.List;\r\nimport java.util.Objects;\r\nimport java.util.concurrent.ExecutionException;\r\nimport java.util.concurrent.ExecutorService;\r\nimport java.util.concurrent.Executors;\r\nimport java.util.concurrent.atomic.AtomicInteger;\r\n\r\nimport org.opencv.android.OpenCVLoader;\r\nimport org.opencv.core.Mat;\r\nimport org.opencv.core.MatOfRect;\r\nimport org.opencv.imgproc.Imgproc;\r\nimport org.opencv.objdetect.CascadeClassifier;\r\nimport org.tensorflow.lite.Interpreter;\r\nimport org.tensorflow.lite.Tensor;\r\nimport org.tensorflow.lite.gpu.GpuDelegate;\r\n\r\nimport android.graphics.Rect;\r\n\r\n\r\npublic class MainActivity extends AppCompatActivity implements ArduinoUsbController.ConnectionCallback {\r\n    private PreviewView previewView;\r\n    private FaceOverlayView overlayView;\r\n    private CascadeClassifier faceCascade;\r\n    private Interpreter tflite;\r\n    private List<String> labels = new ArrayList<>();\r\n    private static final float CONFIDENCE_THRESHOLD = 0.8f;\r\n\r\n    // Model input parameters\r\n    private int inputWidth;\r\n    private int inputHeight;\r\n    private int inputChannels;\r\n\r\n    private Mat yuvMat, rgbMat, grayMat, faceMat;\r\n    private ByteBuffer imgBuffer;\r\n    private ExecutorService executor = Executors.newSingleThreadExecutor();\r\n\r\n    private CameraSelector cameraSelector = CameraSelector.DEFAULT_BACK_CAMERA;\r\n    private ProcessCameraProvider cameraProvider;\r\n    ImageButton btnSwitch, btnCar ;\r\n    //bo qua khung hinh\r\n    private AtomicInteger frameCount = new AtomicInteger(0);\r\n    private static final int FRAME_SKIP_RATE = 3;\r\n\r\n    private ArduinoUsbController arduinoController;\r\n\r\n    private static final String TAG = \"MainActivity\";\r\n\r\n    private LogAdapter logAdapter;\r\n    private RecyclerView logRecyclerView;\r\n\r\n    @RequiresApi(api = Build.VERSION_CODES.TIRAMISU)\r\n    @Override\r\n    protected void onCreate(Bundle savedInstanceState) {\r\n        super.onCreate(savedInstanceState);\r\n        EdgeToEdge.enable(this);\r\n        setContentView(R.layout.activity_main);\r\n        ViewCompat.setOnApplyWindowInsetsListener(findViewById(R.id.main), (v, insets) -> {\r\n            Insets systemBars = insets.getInsets(WindowInsetsCompat.Type.systemBars());\r\n            v.setPadding(systemBars.left, systemBars.top, systemBars.right, systemBars.bottom);\r\n            return insets;\r\n        });\r\n        initView();\r\n        // Khởi tạo OpenCV\r\n        OpenCVLoader.initLocal();\r\n        initializeApp();\r\n    }\r\n\r\n    private void initView() {\r\n        //preview\r\n        previewView = findViewById(R.id.previewView);\r\n        overlayView = findViewById(R.id.overlay);\r\n        btnSwitch = findViewById(R.id.btnSwitchCamera);\r\n        btnCar = findViewById(R.id.btnCar);\r\n\r\n        btnSwitch.setOnClickListener(v -> {\r\n            // Đổi selector\r\n            if (cameraSelector == CameraSelector.DEFAULT_BACK_CAMERA) {\r\n                cameraSelector = CameraSelector.DEFAULT_FRONT_CAMERA;\r\n            } else {\r\n                cameraSelector = CameraSelector.DEFAULT_BACK_CAMERA;\r\n            }\r\n            // Khởi động lại camera với selector mới\r\n            startCamera();\r\n        });\r\n\r\n        //btnCar\r\n        btnCar.setOnClickListener(v->{\r\n            if (arduinoController.isConnected()){\r\n                //huy connect\r\n                if (!arduinoController.disconnect()) {\r\n                    addLogEntry(\"huy ket noi that bai\");\r\n                    return;\r\n                };\r\n                btnCar.setImageResource(R.drawable.car);\r\n                btnCar.setImageTintList(ColorStateList.valueOf(Color.WHITE));\r\n            }else {\r\n                //connect\r\n                if (!arduinoController.connect()) {\r\n                    addLogEntry(\"ket noi that bai\");\r\n                    return;\r\n                };\r\n                btnCar.setImageResource(R.drawable.carstart);\r\n                btnCar.setImageTintList(null);\r\n            }\r\n        });\r\n\r\n        // Khởi tạo log console\r\n        logRecyclerView = findViewById(R.id.logRecyclerView);\r\n        logAdapter = new LogAdapter();\r\n        logRecyclerView.setLayoutManager(new LinearLayoutManager(this));\r\n        logRecyclerView.setAdapter(logAdapter);\r\n    }\r\n\r\n    // Phương thức mới\r\n    private void updateButtonState() {\r\n        runOnUiThread(() -> {\r\n            if (arduinoController.isConnected()) {\r\n                btnCar.setImageResource(R.drawable.carstart);\r\n                btnCar.setImageTintList(null);\r\n            } else {\r\n                btnCar.setImageResource(R.drawable.car);\r\n                btnCar.setImageTintList(ColorStateList.valueOf(Color.WHITE));\r\n            }\r\n        });\r\n    }\r\n\r\n    private void addLogEntry(String message) {\r\n        runOnUiThread(() -> {\r\n            logAdapter.addLog(message);\r\n            logRecyclerView.smoothScrollToPosition(logAdapter.getItemCount() - 1);\r\n        });\r\n    }\r\n\r\n    private void initializeApp() {\r\n        loadCascade();\r\n        loadModel();\r\n        startCamera();\r\n\r\n        if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.TIRAMISU) {\r\n            arduinoController = new ArduinoUsbController(this, this);\r\n        }\r\n    }\r\n\r\n    @SuppressLint(\"NewApi\")\r\n    private void loadModel() {\r\n        try {\r\n            // Load TFLite model\r\n            tflite = new Interpreter(loadModelFile(\"face_model_v6.tflite\"));\r\n//            Interpreter.Options options = new Interpreter.Options();\r\n//            GpuDelegate delegate = new GpuDelegate();\r\n//            options.addDelegate(delegate);\r\n//            tflite = new Interpreter(loadModelFile(\"face_model.tflite\"), options);\r\n//            // Lấy thông số đầu vào\r\n            Tensor inputTensor = tflite.getInputTensor(0);\r\n            int[] inputShape = inputTensor.shape();\r\n            inputWidth = inputShape[1];\r\n            inputHeight = inputShape[2];\r\n            inputChannels = inputShape[3];\r\n\r\n            //load labels\r\n            try {\r\n                InputStream is = getAssets().open(\"labels.txt\");\r\n                byte[] bytes = is.readAllBytes();\r\n                String content = new String(bytes, StandardCharsets.UTF_8);\r\n                labels = Arrays.asList(content.split(\"\\\\r?\\\\n\"));\r\n                is.close();\r\n            } catch (IOException e) {\r\n                Log.e(\"FaceRecognition\", \"Error reading labels.txt\", e);\r\n            }\r\n        } catch (Exception e) {\r\n            Log.e(\"FaceRecognition\", \"Error loading model\", e);\r\n        }\r\n    }\r\n\r\n    private void loadCascade() {\r\n        try {\r\n            InputStream is = getAssets().open(\"haarcascade_frontalface_default.xml\");\r\n            File cascadeFile = new File(getCacheDir(), \"temp.xml\");\r\n\r\n            try (FileOutputStream os = new FileOutputStream(cascadeFile)) {\r\n                byte[] buffer = new byte[4096];\r\n                int bytesRead;\r\n                while ((bytesRead = is.read(buffer)) != -1) {\r\n                    os.write(buffer, 0, bytesRead);\r\n                }\r\n            }\r\n\r\n            faceCascade = new CascadeClassifier(cascadeFile.getAbsolutePath());\r\n            if (faceCascade.empty()) {\r\n                Log.e(\"FaceRecognition\", \"Failed to load cascade classifier\");\r\n            }\r\n\r\n        } catch (Exception e) {\r\n            Log.e(\"FaceRecognition\", \"Error loading cascade\", e);\r\n        }\r\n    }\r\n\r\n    private void startCamera() {\r\n        ListenableFuture<ProcessCameraProvider> future = ProcessCameraProvider.getInstance(this);\r\n        future.addListener(() -> {\r\n            try {\r\n                cameraProvider = future.get();\r\n                // Trước khi bind lại, unbind hết các use-cases cũ\r\n                cameraProvider.unbindAll();\r\n\r\n                // Tạo và cấu hình Preview\r\n                Preview preview = new Preview.Builder().build();\r\n                preview.setSurfaceProvider(previewView.getSurfaceProvider());\r\n\r\n                // Tạo ImageAnalysis\r\n                ImageAnalysis imageAnalysis = new ImageAnalysis.Builder()\r\n                        .setBackpressureStrategy(ImageAnalysis.STRATEGY_KEEP_ONLY_LATEST)\r\n                        .build();\r\n\r\n                imageAnalysis.setAnalyzer(executor, this::analyzeImage);\r\n\r\n                // Bind các use cases vào vòng đời\r\n                cameraProvider.bindToLifecycle(\r\n                        this,\r\n                        cameraSelector,\r\n                        preview,\r\n                        imageAnalysis\r\n                );\r\n\r\n            } catch (ExecutionException | InterruptedException e) {\r\n                Log.e(\"CameraX\", \"Error binding camera\", e);\r\n            }\r\n        }, ContextCompat.getMainExecutor(this));\r\n    }\r\n\r\n    @OptIn(markerClass = ExperimentalGetImage.class)\r\n    private void analyzeImage(@NonNull ImageProxy imageProxy) {\r\n        try {\r\n            // 1. Skip frame\r\n            if (frameCount.getAndIncrement() % FRAME_SKIP_RATE != 0) {\r\n                imageProxy.close();\r\n                return;\r\n            }\r\n\r\n            // 2. Chuyển ImageProxy -> RGB Mat\r\n            rgbMat = yuv420ToRgbMat(Objects.requireNonNull(imageProxy.getImage()));\r\n\r\n            // 3. Xoay đúng chiều theo rotationDegrees\r\n            int rotation = imageProxy.getImageInfo().getRotationDegrees();\r\n            switch (rotation) {\r\n                case 90:\r\n                    Core.rotate(rgbMat, rgbMat, Core.ROTATE_90_CLOCKWISE);\r\n                    break;\r\n                case 180:\r\n                    Core.rotate(rgbMat, rgbMat, Core.ROTATE_180);\r\n                    break;\r\n                case 270:\r\n                    Core.rotate(rgbMat, rgbMat, Core.ROTATE_90_COUNTERCLOCKWISE);\r\n                    break;\r\n                default:\r\n                    // 0 độ: không làm gì\r\n            }\r\n\r\n            // 4. Tính kích thước sau khi xoay\r\n            int rotatedWidth  = rgbMat.cols();\r\n            int rotatedHeight = rgbMat.rows();\r\n\r\n            // 5. Phát hiện khuôn mặt trên ảnh đã xoay\r\n            grayMat = new Mat();\r\n            Imgproc.cvtColor(rgbMat, grayMat, Imgproc.COLOR_RGB2GRAY);\r\n            MatOfRect faces = new MatOfRect();\r\n            faceCascade.detectMultiScale(\r\n                    grayMat, faces,\r\n                    1.1, // scaleFactor (tăng để tăng tốc)\r\n                    3, // minNeighbors\r\n                    0, // flags\r\n                    new Size(100, 100), // minSize (lớn hơn để giảm số lượng kiểm tra)\r\n                    new Size(400, 400)  // maxSize\r\n            );\r\n\r\n            // 6. Xử lý từng face, build results như cũ...\r\n            List<FaceResult> results = new ArrayList<>();\r\n            for (org.opencv.core.Rect rect : faces.toArray()) {\r\n                faceMat = preprocessFace(rgbMat.submat(rect));\r\n                ByteBuffer buffer = convertMatToBuffer(faceMat);\r\n\r\n                // Inference\r\n                float[][] output = new float[1][labels.size()];\r\n                tflite.run(buffer, output);\r\n\r\n                // Xử lý kết quả\r\n                float[] predictions = output[0];\r\n                int classId = getMaxIndex(predictions);\r\n                float confidence = predictions[classId];\r\n\r\n//                int classId = getMaxIndex(output[0]);\r\n//                float confidence = output[0][classId];\r\n                String label = (confidence > CONFIDENCE_THRESHOLD) ?\r\n                        labels.get(classId) : \"Unknown\";\r\n\r\n                // Xử lý nếu là khuôn mặt \"Loc\"\r\n                if (label.equals(\"Loc\")) {\r\n                    // Lấy chiều rộng của khung hình\r\n                    int imageWidth = rgbMat.cols();\r\n\r\n                    // Tính tâm ngang của màn hình (đơn vị pixel)\r\n                    int imageCenterX = imageWidth / 2;\r\n\r\n                    // Tính tâm ngang của khuôn mặt (đơn vị pixel)\r\n                    int faceCenterX = rect.x + rect.width / 2;\r\n\r\n                    // Độ lệch giữa tâm mặt và tâm màn hình\r\n                    int deviation = faceCenterX - imageCenterX;\r\n                    // Độ lệch tối đa có thể (bằng nửa chiều rộng màn hình)\r\n                    int maxDeviation = imageWidth / 2;\r\n\r\n                    //di thang\r\n                    String direction = \"F\";\r\n                    //Ti le mac dinh\r\n                    int ratio = 0;\r\n\r\n                    if (deviation != 0) {\r\n                        // Tính tỉ lệ 0-100 dựa trên độ lệch\r\n//                        ratio = (int) (Math.abs(deviation) / (float) maxDeviation * 100);\r\n//                        ratio = Math.max(0, Math.min(100, ratio)); // Giới hạn tỉ lệ 0-100\r\n\r\n                        direction = deviation < 0 ? \"L\" : \"R\"; // Âm = trái, Dương = phải\r\n                    }\r\n                    sendCommand(direction);\r\n                  //  sendControlCommand(direction, ratio);\r\n//                    connectUsb.sendControlCommand(direction, ratio);\r\n                }\r\n                results.add(new FaceResult(\r\n                        new Rect(rect.x, rect.y, rect.x + rect.width, rect.y + rect.height),\r\n                        label, confidence\r\n                ));\r\n            }\r\n            // 7. Truyền đúng kích thước đã xoay cho overlay\r\n            overlayView.setFaces(results, rotatedWidth, rotatedHeight);\r\n        } catch (Exception e) {\r\n            Log.e(\"FaceRecognition\", \"Analysis error\", e);\r\n        } finally {\r\n            imageProxy.close();\r\n        }\r\n    }\r\n    //'F': Tiến\r\n    //'B': Lùi\r\n    //'L': Rẽ trái\r\n    //'R': Rẽ phải\r\n    //'S': Dừng\r\n\r\n    private void sendControlCommand(String direction, int ratio) {\r\n        String data = direction + (direction.equals(\"W\") ? \"\" : ratio);\r\n       // Log.d(\"Control\", \"Sending command: \" + data);\r\n\r\n        sendCommand(data);\r\n    }\r\n\r\n    private void sendCommand(String direction) {\r\n        if (arduinoController.isConnected()) {\r\n            arduinoController.sendControlCommand(direction);\r\n            addLogEntry(\"Đã gửi lệnh: \" + direction);\r\n//            Log.d(TAG, \"Đã gửi lệnh: \" + direction);\r\n//            Toast.makeText(this, \"Đã gửi lệnh: \" + direction, Toast.LENGTH_SHORT).show();\r\n        } else {\r\n            addLogEntry(\"Chưa kết nối thiết bị. Lệnh: \"+ direction);\r\n//            Log.d(TAG, \"Chưa kết nối thiết bị. Lệnh: \"+ direction);\r\n//            Toast.makeText(this, \"Chưa kết nối thiết bị\", Toast.LENGTH_SHORT).show();\r\n        }\r\n    }\r\n\r\n    private Mat yuv420ToRgbMat(Image image) {\r\n        // Lấy thông số ảnh\r\n        int width = image.getWidth();\r\n        int height = image.getHeight();\r\n\r\n        // Lấy các planes YUV\r\n        Image.Plane yPlane = image.getPlanes()[0];\r\n        Image.Plane uPlane = image.getPlanes()[1];\r\n        Image.Plane vPlane = image.getPlanes()[2];\r\n\r\n        // Chuẩn bị buffer và mảng byte\r\n        ByteBuffer yBuffer = yPlane.getBuffer();\r\n        ByteBuffer uBuffer = uPlane.getBuffer();\r\n        ByteBuffer vBuffer = vPlane.getBuffer();\r\n\r\n        // Tạo mảng byte cho YUV data (NV21 format)\r\n        byte[] yuvBytes = new byte[yBuffer.remaining() + vBuffer.remaining() + uBuffer.remaining()];\r\n\r\n        // Điền dữ liệu Y\r\n        yBuffer.get(yuvBytes, 0, yBuffer.remaining());\r\n\r\n        // Điền dữ liệu V và U (NV21: Y + VU)\r\n        vBuffer.get(yuvBytes, yBuffer.remaining(), vBuffer.remaining());\r\n        uBuffer.get(yuvBytes, yBuffer.remaining() + vBuffer.remaining(), uBuffer.remaining());\r\n\r\n        // Tạo Mat YUV\r\n        yuvMat = new Mat(height + height/2, width, CvType.CV_8UC1);\r\n        yuvMat.put(0, 0, yuvBytes); // Copy toàn bộ dữ liệu vào Mat\r\n\r\n        // Chuyển YUV → RGB\r\n        rgbMat = new Mat();\r\n        Imgproc.cvtColor(yuvMat, rgbMat, Imgproc.COLOR_YUV2RGB_NV21);\r\n        image.close();\r\n        return rgbMat;\r\n    }\r\n\r\n//    private Mat preprocessFace(Mat faceRoi) {\r\n//        Mat resized = new Mat();\r\n//        Imgproc.resize(faceRoi, resized, new Size(inputWidth, inputHeight));\r\n//\r\n//        // Đảm bảo định dạng uint8\r\n//        if (resized.type() != CvType.CV_8UC3) {\r\n//            resized.convertTo(resized, CvType.CV_8UC3);\r\n//        }\r\n//        return resized;\r\n//    }\r\n\r\n    private Mat preprocessFace(Mat faceRoi) {\r\n        // 1) Resize về đúng kích thước model yêu cầu\r\n        Mat resized = new Mat();\r\n        Imgproc.resize(faceRoi, resized, new Size(inputWidth, inputHeight));\r\n\r\n        // 2) Chuyển sang float32 và chia 255.0 để chuẩn hóa về [0,1]\r\n        Mat floatMat = new Mat();\r\n        resized.convertTo(floatMat, CvType.CV_32FC3, 1.0 / 255.0);\r\n\r\n        // 3) Nếu model train trên RGB, chuyển BGR→RGB\r\n        Imgproc.cvtColor(floatMat, floatMat, Imgproc.COLOR_BGR2RGB);\r\n\r\n        return floatMat;\r\n    }\r\n\r\n    // Sửa hàm convertMatToBuffer\r\n//    private ByteBuffer convertMatToBuffer(Mat mat) {\r\n//        // Đảm bảo Mat là UINT8\r\n//        if (mat.type() != CvType.CV_8UC3) {\r\n//            mat.convertTo(mat, CvType.CV_8UC3);\r\n//        }\r\n//\r\n//        // Tạo buffer với kiểu UINT8\r\n//        imgBuffer = ByteBuffer.allocateDirect(inputWidth * inputHeight * 3);\r\n//        imgBuffer.order(ByteOrder.nativeOrder());\r\n//\r\n//        // Điền dữ liệu byte (0-255)\r\n//        byte[] pixelData = new byte[(int) mat.total() * mat.channels()];\r\n//        mat.get(0, 0, pixelData);\r\n//        imgBuffer.put(pixelData);\r\n//        imgBuffer.rewind();\r\n//\r\n//        return imgBuffer;\r\n//    }\r\n\r\n    private ByteBuffer convertMatToBuffer(Mat floatMat) {\r\n        // Số byte = 4 bytes * H * W * 3 channels\r\n        int byteCount = 4 * inputWidth * inputHeight * inputChannels;\r\n        ByteBuffer fb = ByteBuffer.allocateDirect(byteCount);\r\n        fb.order(ByteOrder.nativeOrder());\r\n\r\n        float[] pixel = new float[inputChannels];\r\n        // Duyệt từng pixel và putFloat\r\n        for (int y = 0; y < inputHeight; y++) {\r\n            for (int x = 0; x < inputWidth; x++) {\r\n                floatMat.get(y, x, pixel);\r\n                // Nếu thứ tự kênh đã là RGB, giữ nguyên:\r\n                fb.putFloat(pixel[0]);\r\n                fb.putFloat(pixel[1]);\r\n                fb.putFloat(pixel[2]);\r\n            }\r\n        }\r\n        fb.rewind();\r\n        return fb;\r\n    }\r\n\r\n    private int getMaxIndex(float[] array) {\r\n        int maxIndex = 0;\r\n        for (int i = 1; i < array.length; i++) {\r\n            if (array[i] > array[maxIndex]) maxIndex = i;\r\n        }\r\n        return maxIndex;\r\n    }\r\n\r\n    private ByteBuffer loadModelFile(String modelName) throws IOException {\r\n        try (InputStream is = getAssets().open(modelName)) {\r\n            ByteBuffer buffer = ByteBuffer.allocateDirect(is.available());\r\n            byte[] bytes = new byte[is.available()];\r\n            is.read(bytes);\r\n            buffer.put(bytes);\r\n            buffer.rewind();\r\n            return buffer;\r\n        }\r\n    }\r\n\r\n    @Override\r\n    protected void onDestroy() {\r\n        super.onDestroy();\r\n        executor.shutdown();\r\n        arduinoController.release();\r\n    }\r\n\r\n    //xu ly sau khi duoc cap quyen\r\n    @Override\r\n    public void onRequestPermissionsResult(int requestCode, String[] permissions, int[] grantResults) {\r\n        super.onRequestPermissionsResult(requestCode, permissions, grantResults);\r\n        if (requestCode == 100) {\r\n            if (grantResults.length > 0 && grantResults[0] == PackageManager.PERMISSION_GRANTED) {\r\n                startCamera();\r\n            } else {\r\n                Toast.makeText(this, \"Cần cấp quyền camera\", Toast.LENGTH_SHORT).show();\r\n            }\r\n        }\r\n    }\r\n\r\n    @Override\r\n    public void onConnectionStatusChange(String status) {\r\n        addLogEntry(\"status:\" + status);\r\n    }\r\n\r\n    @Override\r\n    public void onDataReceived(String data) {\r\n        addLogEntry(\"data: \" + data);\r\n    }\r\n\r\n    @Override\r\n    public void onConnectionError(String error) {\r\n        addLogEntry(\"con err\" + error);\r\n    }\r\n}
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/app/src/main/java/com/example/projectxetuhanh/MainActivity.java b/app/src/main/java/com/example/projectxetuhanh/MainActivity.java
--- a/app/src/main/java/com/example/projectxetuhanh/MainActivity.java	(revision 4f3ac39c98a7c2abeef2310383d2023a0fa1203d)
+++ b/app/src/main/java/com/example/projectxetuhanh/MainActivity.java	(date 1746714771534)
@@ -343,9 +343,8 @@
                 tflite.run(buffer, output);
 
                 // Xử lý kết quả
-                float[] predictions = output[0];
-                int classId = getMaxIndex(predictions);
-                float confidence = predictions[classId];
+                int classId = getMaxIndex(output[0]);
+                float confidence = output[0][classId];
 
 //                int classId = getMaxIndex(output[0]);
 //                float confidence = output[0][classId];
@@ -480,7 +479,7 @@
         resized.convertTo(floatMat, CvType.CV_32FC3, 1.0 / 255.0);
 
         // 3) Nếu model train trên RGB, chuyển BGR→RGB
-        Imgproc.cvtColor(floatMat, floatMat, Imgproc.COLOR_BGR2RGB);
+      //  Imgproc.cvtColor(floatMat, floatMat, Imgproc.COLOR_BGR2RGB);
 
         return floatMat;
     }
